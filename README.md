# MoE-Classifier: MoE-Gating for RAG
Infers routing decisions based on synthetic user prompts that are agentically generated by clustering each RAG-Experts knowledge base.
---

### Project Overview
This project is a component of a larger system I have been devloping, a combination of MoE and Retreival Augmentaion where each expert is a RAG system
whose knowledge base is composed of all available class material for a specific course. This particular component is in charge of infering which of a student's courses
the student's prompt is intended to query, and selecting the appropiate expert.

### Data Generation
The data used for this classifier is composed of synthetic user queries. These queries are generated by clustering the vector embeddings of each RAG-Expert's knowledge base and using the cluster's extracted text as context for GPT-3.5. GPT-3.5 takes this context and is prompted to generate probable queries relating to the context generated by each cluster. The idea being that these clusters represent some vague form of "course sections" due to teh fact that they were generated somewhat 'semantically'.

The resulting synthetic queries are then labeled by their origin course name, and stored as a large dataframe. This frame is then split into train, validation and test sets and each synthetic query is tokenized and each label is one-hot encoded respectively. These datasets are saved as HuggingFace datasets in '.arrow' format for ease of use.

### Methods Overview
- In progress

### Results
- In progress
